{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk import download, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, RSLPStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df_train = pd.read_excel('./1. data_raw/train.xlsx')\n",
    "airbnb_df_test = pd.read_excel('./1. data_raw/test.xlsx')\n",
    "airbnb_df_train_reviews = pd.read_excel('./1. data_raw/train_reviews.xlsx')\n",
    "airbnb_df_test_reviews = pd.read_excel('./1. data_raw/test_reviews.xlsx')\n",
    "pd.options.display.max_colwidth = 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12496, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721402, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_df_train_reviews.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language detection for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df_train_reviews[\"lang_comments\"] = airbnb_df_train_reviews[\"comments\"].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comments</th>\n",
       "      <th>lang_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a very cozy and comfortable house to s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>good&lt;br/&gt;</td>\n",
       "      <td>cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>My first hostel experience, and all I have to ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Das Hostel war neu und deshalb funktionierte a...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>It was fine for a dorm, but I think for the pe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721397</th>\n",
       "      <td>12494</td>\n",
       "      <td>We had a good time, the apartment has a great ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721398</th>\n",
       "      <td>12494</td>\n",
       "      <td>Great apartment in very central location. The ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721399</th>\n",
       "      <td>12494</td>\n",
       "      <td>We are Airbnb Super Hosts too, so trust me, Li...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721400</th>\n",
       "      <td>12494</td>\n",
       "      <td>We had a lovely stay at this apartment. Sofia ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721401</th>\n",
       "      <td>12494</td>\n",
       "      <td>Clean, very good position, easy checkin, the p...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721402 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                           comments lang_comments\n",
       "0           1  this is a very cozy and comfortable house to s...            en\n",
       "1           1                                          good<br/>            cy\n",
       "2           1  My first hostel experience, and all I have to ...            en\n",
       "3           1  Das Hostel war neu und deshalb funktionierte a...            de\n",
       "4           1  It was fine for a dorm, but I think for the pe...            en\n",
       "...       ...                                                ...           ...\n",
       "721397  12494  We had a good time, the apartment has a great ...            en\n",
       "721398  12494  Great apartment in very central location. The ...            en\n",
       "721399  12494  We are Airbnb Super Hosts too, so trust me, Li...            en\n",
       "721400  12494  We had a lovely stay at this apartment. Sofia ...            en\n",
       "721401  12494  Clean, very good position, easy checkin, the p...            en\n",
       "\n",
       "[721402 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_df_train_reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language detection for desc/host_about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df_train[\"lang_desc\"] = airbnb_df_train[\"description\"].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df_train[\"lang_host\"] = airbnb_df_train[\"host_about\"].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>host_about</th>\n",
       "      <th>unlisted</th>\n",
       "      <th>lang_desc</th>\n",
       "      <th>lang_host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a shared mixed room in our hostel, wit...</td>\n",
       "      <td>Alojamento Local Registro: 20835/AL</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>O meu espaço fica perto de Parque Eduardo VII,...</td>\n",
       "      <td>I am friendly host, and I will try to always b...</td>\n",
       "      <td>1</td>\n",
       "      <td>pt</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Trafaria’s House is a cozy and familiar villa ...</td>\n",
       "      <td>I am a social person liking to communicate, re...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Apartamento Charmoso no Chiado, Entre o Largo ...</td>\n",
       "      <td>Hello!_x000D_\\nI m Portuguese and i love to me...</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Joli appartement  en bordure de mer.&lt;br /&gt; 2 m...</td>\n",
       "      <td>Nous sommes une famille avec deux enfants de 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>12492</td>\n",
       "      <td>CAT’S BY BAIRRO ALTO&lt;br /&gt;&lt;br /&gt;This cozy apar...</td>\n",
       "      <td>Travelling is one of my favorite hobbies. I've...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12492</th>\n",
       "      <td>12493</td>\n",
       "      <td>Beautifully located in the heart of Lisbon's h...</td>\n",
       "      <td>Founded by travel enthusiasts (just like you) ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12493</th>\n",
       "      <td>12494</td>\n",
       "      <td>Enjoy breakfast in the sleek kitchen with its ...</td>\n",
       "      <td>I´m from Portugal and I love to dance and to t...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12494</th>\n",
       "      <td>12495</td>\n",
       "      <td>A Terra da Eira é uma casa de campo rodeada de...</td>\n",
       "      <td>Somos uma familia de 5. Gostamos de viajar e d...</td>\n",
       "      <td>1</td>\n",
       "      <td>pt</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>12496</td>\n",
       "      <td>This brandnew Apartment combines elegant charm...</td>\n",
       "      <td>We are a German-Portuguese couple with a Passi...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12496 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                        description  \\\n",
       "0          1  This is a shared mixed room in our hostel, wit...   \n",
       "1          2  O meu espaço fica perto de Parque Eduardo VII,...   \n",
       "2          3  Trafaria’s House is a cozy and familiar villa ...   \n",
       "3          4  Apartamento Charmoso no Chiado, Entre o Largo ...   \n",
       "4          5  Joli appartement  en bordure de mer.<br /> 2 m...   \n",
       "...      ...                                                ...   \n",
       "12491  12492  CAT’S BY BAIRRO ALTO<br /><br />This cozy apar...   \n",
       "12492  12493  Beautifully located in the heart of Lisbon's h...   \n",
       "12493  12494  Enjoy breakfast in the sleek kitchen with its ...   \n",
       "12494  12495  A Terra da Eira é uma casa de campo rodeada de...   \n",
       "12495  12496  This brandnew Apartment combines elegant charm...   \n",
       "\n",
       "                                              host_about  unlisted lang_desc  \\\n",
       "0                    Alojamento Local Registro: 20835/AL         0        en   \n",
       "1      I am friendly host, and I will try to always b...         1        pt   \n",
       "2      I am a social person liking to communicate, re...         1        en   \n",
       "3      Hello!_x000D_\\nI m Portuguese and i love to me...         0        pt   \n",
       "4      Nous sommes une famille avec deux enfants de 1...         0        fr   \n",
       "...                                                  ...       ...       ...   \n",
       "12491  Travelling is one of my favorite hobbies. I've...         0        en   \n",
       "12492  Founded by travel enthusiasts (just like you) ...         0        en   \n",
       "12493  I´m from Portugal and I love to dance and to t...         0        en   \n",
       "12494  Somos uma familia de 5. Gostamos de viajar e d...         1        pt   \n",
       "12495  We are a German-Portuguese couple with a Passi...         1        en   \n",
       "\n",
       "      lang_host  \n",
       "0            pt  \n",
       "1            en  \n",
       "2            en  \n",
       "3            en  \n",
       "4            fr  \n",
       "...         ...  \n",
       "12491        en  \n",
       "12492        en  \n",
       "12493        en  \n",
       "12494        pt  \n",
       "12495        en  \n",
       "\n",
       "[12496 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import detected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_detected = pd.read_csv(\"./2. data_detected/airbnb_df_train_detected.csv\", index_col=\"index\",).drop(\"Unnamed: 0\",axis=1)\n",
    "df_train_reviews_detected = pd.read_csv(\"./2. data_detected/airbnb_df_train__reviews_detected.csv\", index_col=\"index\").drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of different Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airbnb_df_train[\"lang_desc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airbnb_df_train[\"lang_host\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airbnb_df_train_reviews[\"lang_comments\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df, df_review, language):\n",
    "\n",
    "    columns_to_drop = ['lang_desc', 'lang_host']\n",
    "    \n",
    "    df = df[(df['lang_desc'] == language) & (df['lang_host'] == language)]\n",
    "    df_review = df_review[df_review['lang_comments'] == language]\n",
    "    grouped_reviews = df_review.groupby('index')['comments'].apply(lambda x: ''.join(str(x))).reset_index()\n",
    "    merged_df = pd.merge(df, grouped_reviews, on='index', how='left')\n",
    "    merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "    merged_df = merged_df[[\"index\",\t\"description\", \"host_about\", \"comments\", \"unlisted\"]]\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join all English host_about/desc with English comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_english = create_df(df_train_detected, df_train_reviews_detected, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>host_about</th>\n",
       "      <th>comments</th>\n",
       "      <th>unlisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>trafaria house cozy familiar villa facility ne...</td>\n",
       "      <td>social person liking communicate reading trave...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>important response covid property extended cle...</td>\n",
       "      <td>hi homing company develops activity tourism pr...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>home rent traveling perfect vacation without c...</td>\n",
       "      <td>globe trotter portuguese nationality german fa...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>find tranquility meticulously curated lifestyl...</td>\n",
       "      <td>travel lot love x originally israel currently ...</td>\n",
       "      <td>index shani helpful throughout process accommo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>charming apartment one bedroom double bed doub...</td>\n",
       "      <td>isabel helder portuguese parent three wonderfu...</td>\n",
       "      <td>index great little space lovely host clean w c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>12489</td>\n",
       "      <td>feel home wherever choose live blueground love...</td>\n",
       "      <td>blueground global proptech company several tho...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>12492</td>\n",
       "      <td>cat bairro alto cozy apartment lisbon city cen...</td>\n",
       "      <td>travelling one favorite hobby already visited ...</td>\n",
       "      <td>index happy find place com great stay lisbon a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>12493</td>\n",
       "      <td>beautifully located heart lisbon historic cent...</td>\n",
       "      <td>founded travel enthusiast like bnbird want con...</td>\n",
       "      <td>index nice place nice location easy communicat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8204</th>\n",
       "      <td>12494</td>\n",
       "      <td>enjoy eakfast sleek kitchen freestanding knott...</td>\n",
       "      <td>portugal love dance travel x pleasure welcome ...</td>\n",
       "      <td>index lovely stay lisbon apartm liliana apartm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>12496</td>\n",
       "      <td>andnew apartment combine elegant charme excell...</td>\n",
       "      <td>german portuguese couple passion travel design...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8206 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                        description  \\\n",
       "0         3  trafaria house cozy familiar villa facility ne...   \n",
       "1         6  important response covid property extended cle...   \n",
       "2         7  home rent traveling perfect vacation without c...   \n",
       "3         8  find tranquility meticulously curated lifestyl...   \n",
       "4         9  charming apartment one bedroom double bed doub...   \n",
       "...     ...                                                ...   \n",
       "8201  12489  feel home wherever choose live blueground love...   \n",
       "8202  12492  cat bairro alto cozy apartment lisbon city cen...   \n",
       "8203  12493  beautifully located heart lisbon historic cent...   \n",
       "8204  12494  enjoy eakfast sleek kitchen freestanding knott...   \n",
       "8205  12496  andnew apartment combine elegant charme excell...   \n",
       "\n",
       "                                             host_about  \\\n",
       "0     social person liking communicate reading trave...   \n",
       "1     hi homing company develops activity tourism pr...   \n",
       "2     globe trotter portuguese nationality german fa...   \n",
       "3     travel lot love x originally israel currently ...   \n",
       "4     isabel helder portuguese parent three wonderfu...   \n",
       "...                                                 ...   \n",
       "8201  blueground global proptech company several tho...   \n",
       "8202  travelling one favorite hobby already visited ...   \n",
       "8203  founded travel enthusiast like bnbird want con...   \n",
       "8204  portugal love dance travel x pleasure welcome ...   \n",
       "8205  german portuguese couple passion travel design...   \n",
       "\n",
       "                                               comments  unlisted  \n",
       "0                                                   nan         1  \n",
       "1                                                   nan         0  \n",
       "2                                                   nan         1  \n",
       "3     index shani helpful throughout process accommo...         0  \n",
       "4     index great little space lovely host clean w c...         0  \n",
       "...                                                 ...       ...  \n",
       "8201                                                nan         1  \n",
       "8202  index happy find place com great stay lisbon a...         0  \n",
       "8203  index nice place nice location easy communicat...         0  \n",
       "8204  index lovely stay lisbon apartm liliana apartm...         0  \n",
       "8205                                                nan         1  \n",
       "\n",
       "[8206 rows x 5 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_english"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems like NaN values is a good indication if a flat is getting listed again or not. Makes sense in real life context, because flats that dont have visitors are more likly to be unlisted in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_eng(row, tokenize, stop, lemmatize, stemmertize):\n",
    "    updates = []\n",
    "    \n",
    "    for j in tqdm(row):\n",
    "        \n",
    "        text = j\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA and PUNCTUATION\n",
    "        text = re.sub(\"[^a-zA-Z]\",\" \", text )\n",
    "        text = re.sub(\"br\", \"\", text)\n",
    "\n",
    "        if tokenize:\n",
    "            tokens = word_tokenize(text)\n",
    "            text = \" \".join(tokens)\n",
    "        \n",
    "        #REMOVE STOPWORDS\n",
    "        if stop:\n",
    "            stop_eng = set(stopwords.words('english'))\n",
    "            text = \" \".join([word for word in text.split() if word not in stop_eng])\n",
    "        \n",
    "        #Lemmatize\n",
    "        if lemmatize:\n",
    "            lemma_eng = WordNetLemmatizer()\n",
    "            text = \" \".join(lemma_eng.lemmatize(word) for word in text.split())\n",
    "        \n",
    "        #Stemming\n",
    "        if stemmertize:\n",
    "            stemmer_eng = SnowballStemmer('english')\n",
    "            text = \" \".join(stemmer_eng.stem(word) for word in text.split())\n",
    "            \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\leoal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leoal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\leoal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 8206/8206 [00:05<00:00, 1459.60it/s]\n",
      "100%|██████████| 8206/8206 [00:03<00:00, 2143.77it/s]\n",
      "100%|██████████| 8206/8206 [00:04<00:00, 1779.09it/s]\n"
     ]
    }
   ],
   "source": [
    "download('wordnet')\n",
    "download('stopwords')\n",
    "download('punkt')\n",
    "columns_to_apply = ['description', 'host_about', 'comments']\n",
    "merged_df_english[columns_to_apply] = merged_df_english[columns_to_apply].astype(str).apply(lambda row: preprocessing_eng(row=row,\n",
    "                                                                                                                        tokenize=True,\n",
    "                                                                                                                        stop=True,\n",
    "                                                                                                                        lemmatize = True, \n",
    "                                                                                                                        stemmertize = False\n",
    "                                                                                                                        )\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>host_about</th>\n",
       "      <th>comments</th>\n",
       "      <th>unlisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>trafaria house cozy familiar villa facility ne...</td>\n",
       "      <td>social person liking communicate reading trave...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>important response covid property extended cle...</td>\n",
       "      <td>hi homing company develops activity tourism pr...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>home rent traveling perfect vacation without c...</td>\n",
       "      <td>globe trotter portuguese nationality german fa...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>find tranquility meticulously curated lifestyl...</td>\n",
       "      <td>travel lot love x originally israel currently ...</td>\n",
       "      <td>index shani helpful throughout process accommo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>charming apartment one bedroom double bed doub...</td>\n",
       "      <td>isabel helder portuguese parent three wonderfu...</td>\n",
       "      <td>index great little space lovely host clean w c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>12489</td>\n",
       "      <td>feel home wherever choose live blueground love...</td>\n",
       "      <td>blueground global proptech company several tho...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>12492</td>\n",
       "      <td>cat bairro alto cozy apartment lisbon city cen...</td>\n",
       "      <td>travelling one favorite hobby already visited ...</td>\n",
       "      <td>index happy find place com great stay lisbon a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>12493</td>\n",
       "      <td>beautifully located heart lisbon historic cent...</td>\n",
       "      <td>founded travel enthusiast like bnbird want con...</td>\n",
       "      <td>index nice place nice location easy communicat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8204</th>\n",
       "      <td>12494</td>\n",
       "      <td>enjoy eakfast sleek kitchen freestanding knott...</td>\n",
       "      <td>portugal love dance travel x pleasure welcome ...</td>\n",
       "      <td>index lovely stay lisbon apartm liliana apartm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>12496</td>\n",
       "      <td>andnew apartment combine elegant charme excell...</td>\n",
       "      <td>german portuguese couple passion travel design...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8206 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                        description  \\\n",
       "0         3  trafaria house cozy familiar villa facility ne...   \n",
       "1         6  important response covid property extended cle...   \n",
       "2         7  home rent traveling perfect vacation without c...   \n",
       "3         8  find tranquility meticulously curated lifestyl...   \n",
       "4         9  charming apartment one bedroom double bed doub...   \n",
       "...     ...                                                ...   \n",
       "8201  12489  feel home wherever choose live blueground love...   \n",
       "8202  12492  cat bairro alto cozy apartment lisbon city cen...   \n",
       "8203  12493  beautifully located heart lisbon historic cent...   \n",
       "8204  12494  enjoy eakfast sleek kitchen freestanding knott...   \n",
       "8205  12496  andnew apartment combine elegant charme excell...   \n",
       "\n",
       "                                             host_about  \\\n",
       "0     social person liking communicate reading trave...   \n",
       "1     hi homing company develops activity tourism pr...   \n",
       "2     globe trotter portuguese nationality german fa...   \n",
       "3     travel lot love x originally israel currently ...   \n",
       "4     isabel helder portuguese parent three wonderfu...   \n",
       "...                                                 ...   \n",
       "8201  blueground global proptech company several tho...   \n",
       "8202  travelling one favorite hobby already visited ...   \n",
       "8203  founded travel enthusiast like bnbird want con...   \n",
       "8204  portugal love dance travel x pleasure welcome ...   \n",
       "8205  german portuguese couple passion travel design...   \n",
       "\n",
       "                                               comments  unlisted  \n",
       "0                                                   nan         1  \n",
       "1                                                   nan         0  \n",
       "2                                                   nan         1  \n",
       "3     index shani helpful throughout process accommo...         0  \n",
       "4     index great little space lovely host clean w c...         0  \n",
       "...                                                 ...       ...  \n",
       "8201                                                nan         1  \n",
       "8202  index happy find place com great stay lisbon a...         0  \n",
       "8203  index nice place nice location easy communicat...         0  \n",
       "8204  index lovely stay lisbon apartm liliana apartm...         0  \n",
       "8205                                                nan         1  \n",
       "\n",
       "[8206 rows x 5 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_english"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join all French host_about/desc with French comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_french = create_df(df_train_detected, df_train_reviews_detected, \"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>host_about</th>\n",
       "      <th>comments</th>\n",
       "      <th>unlisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Joli appartement  en bordure de mer.&lt;br /&gt; 2 m...</td>\n",
       "      <td>Nous sommes une famille avec deux enfants de 1...</td>\n",
       "      <td>index\\n5    Un très bel appartement avec une m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>Hostel dans maison de ville , location possibl...</td>\n",
       "      <td>Maison typique avec trois chambres individuell...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>Appartement très chaleureux, avec beaucoup de ...</td>\n",
       "      <td>Je suis teresa, novice dans le domaines de la ...</td>\n",
       "      <td>index\\n192    Appartement spacieux et propre, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>Chambre double tout confort dans grande maison...</td>\n",
       "      <td>Couple de français installé au Portugal où nou...</td>\n",
       "      <td>index\\n301    Tout d’abord une très belle prop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329</td>\n",
       "      <td>Situé au pied du Panthéon dans le quartier de ...</td>\n",
       "      <td>Romain et moi sommes un couple qui sommes tomb...</td>\n",
       "      <td>index\\n329    Appartement très bien situé dans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>11799</td>\n",
       "      <td>Appartement de 2 pièces entièrement rénové se ...</td>\n",
       "      <td>Bonjour, je m’appelle Leo, un français d’origi...</td>\n",
       "      <td>index\\n11799    Accueil très chaleureux de Ped...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>11878</td>\n",
       "      <td>Chambre sexy in-love. Chambre avec de nombreux...</td>\n",
       "      <td>Avec mon mari Dominique, nous vous proposons à...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>11997</td>\n",
       "      <td>Ce logement affiche un style résolument unique...</td>\n",
       "      <td>j'aime les paisagem la montagne et tout qui c'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>12210</td>\n",
       "      <td>Jolie maison typique portugaise et entièrement...</td>\n",
       "      <td>Christophe &amp; Lila marié . Trois enfants</td>\n",
       "      <td>index\\n12210    Nous avons passé un très bon d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>12264</td>\n",
       "      <td>Si vous souhaitez une immersion dans le Lisbon...</td>\n",
       "      <td>Je suis Isabelle\\nj´ai une fille de 22 ans étu...</td>\n",
       "      <td>index\\n12264    Super appartement à Mouraria, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                        description  \\\n",
       "0        5  Joli appartement  en bordure de mer.<br /> 2 m...   \n",
       "1      189  Hostel dans maison de ville , location possibl...   \n",
       "2      192  Appartement très chaleureux, avec beaucoup de ...   \n",
       "3      301  Chambre double tout confort dans grande maison...   \n",
       "4      329  Situé au pied du Panthéon dans le quartier de ...   \n",
       "..     ...                                                ...   \n",
       "100  11799  Appartement de 2 pièces entièrement rénové se ...   \n",
       "101  11878  Chambre sexy in-love. Chambre avec de nombreux...   \n",
       "102  11997  Ce logement affiche un style résolument unique...   \n",
       "103  12210  Jolie maison typique portugaise et entièrement...   \n",
       "104  12264  Si vous souhaitez une immersion dans le Lisbon...   \n",
       "\n",
       "                                            host_about  \\\n",
       "0    Nous sommes une famille avec deux enfants de 1...   \n",
       "1    Maison typique avec trois chambres individuell...   \n",
       "2    Je suis teresa, novice dans le domaines de la ...   \n",
       "3    Couple de français installé au Portugal où nou...   \n",
       "4    Romain et moi sommes un couple qui sommes tomb...   \n",
       "..                                                 ...   \n",
       "100  Bonjour, je m’appelle Leo, un français d’origi...   \n",
       "101  Avec mon mari Dominique, nous vous proposons à...   \n",
       "102  j'aime les paisagem la montagne et tout qui c'...   \n",
       "103           Christophe & Lila marié . Trois enfants    \n",
       "104  Je suis Isabelle\\nj´ai une fille de 22 ans étu...   \n",
       "\n",
       "                                              comments  unlisted  \n",
       "0    index\\n5    Un très bel appartement avec une m...         0  \n",
       "1                                                  NaN         0  \n",
       "2    index\\n192    Appartement spacieux et propre, ...         0  \n",
       "3    index\\n301    Tout d’abord une très belle prop...         0  \n",
       "4    index\\n329    Appartement très bien situé dans...         1  \n",
       "..                                                 ...       ...  \n",
       "100  index\\n11799    Accueil très chaleureux de Ped...         0  \n",
       "101                                                NaN         0  \n",
       "102                                                NaN         1  \n",
       "103  index\\n12210    Nous avons passé un très bon d...         0  \n",
       "104  index\\n12264    Super appartement à Mouraria, ...         0  \n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_french"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fr(row, tokenize, stop, lemmatize, stemmertize):\n",
    "    updates = []\n",
    "    \n",
    "    for j in tqdm(row):\n",
    "        \n",
    "        text = j\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA and PUNCTUATION\n",
    "        text = re.sub(\"[^a-zA-Z]\",\" \", text )\n",
    "        text = re.sub(\"br\", \"\", text)\n",
    "\n",
    "        if tokenize:\n",
    "            tokens = word_tokenize(text, language=\"french\")\n",
    "            text = \" \".join(tokens)\n",
    "            \n",
    "        #REMOVE STOPWORDS\n",
    "        if stop:\n",
    "            stop_fr = set(stopwords.words('french'))\n",
    "            text = \" \".join([word for word in text.split() if word not in stop_fr])\n",
    "        \n",
    "        print(text)\n",
    "\n",
    "        #Lemmatize\n",
    "        if lemmatize:\n",
    "            lemma_fr = spacy.load(\"fr_core_news_md\")\n",
    "            doc = lemma_fr(text)\n",
    "            for word in doc:\n",
    "                text = \" \".join(word.lemma_).split()\n",
    "        \n",
    "        #Stemming\n",
    "        if stemmertize:\n",
    "            stemmer_fr = SnowballStemmer('french')\n",
    "            stem_doc = stemmer_fr(text)\n",
    "            for word in stem_doc:\n",
    "                text = \" \".join(stemmer_fr.stem(word) for word in text.split())\n",
    "            \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\leoal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leoal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "  0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joli appartement bordure mer min a pied plage vue magnifique oc an e tage petit balcon chames lit double deux lits separ salle bains douche italienne cuisine enti rement quip e salon canap lit parking gratuit place mini golf restaurants caf supermarch a disposition bas immeuble a km lisbonne proche zones touristiques parc a th dinopark obidos budhha eden jardin oriental ile berlengas etc b the space b logement totalement r nov vue magnifique oc an b license number b al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/105 [00:01<02:27,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hostel maison ville location possible chame individuellement a jardinet jaccuzzi relaxer retours commun tous r sidents salle bain baignoire lave linge salle eau douche salon tv wifi gratuit coin tente flipper cuisine tte quip e salle manger verri re vue jardinet jaccuzzi proche lisbonne centre sintra plages casinos estoril cascais b the space b tranquillit endroit malgr ville coin calme proches toutes commodit at acc facile rendre diff rents endroits typiques visiter tel lisbonne sintra cascais estoril mafra cabo da roca mafra tant autres agr able entre amis famille quipements b guest access b tous endroits puisque maison individuelle uniquement chames priv b license number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/105 [00:02<02:18,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appartement tr chaleureux beaucoup luminosit b license number b al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/105 [00:04<02:17,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chame double tout confort grande maison terrain piscine jaccuzzi nomeuses activit situ e petit village quelques commerces bars ur sites touristiques km plages oc anes km lisbonne pied montejunto cette chame a salle bain wc priv wi fi gratuit disposez activit ext rieures int rieures ainsi certains espaces maison accueil salons bar salle manger b license number b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/105 [00:05<02:15,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "situ pied panth quartier alfama venez journer cet appartement ambiance cosy r cemment r nov quartier typiquement portugais emplacement id al deux restaurants commerces magnifiques vues panoramiques permettra profiter jour proche tram couvrirez mani re agr able gastronomie portugaise fado magnifiques paysages ville collines calme quip accueillir personnes b the space b logement b fice emplacement parfait minute pied panth nacional monuments plus visit lisbonne situ immeuble typiquement portugais duira gr confort quipements modernes charme afin offrir jour inoubliable logement offre situation calme donnant rue pi tonne o pourrez galement profiter patio privatif appartement quip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5/105 [00:06<02:17,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambiance boheme cet appartement rez jardin pouvez relaxer apr avoir visiter lisbonne mardi samedi bas rue trouverez march puces ainsi lieux embl matiques visiter o miradouro eglise da graca o panteon national wifi fie perfect b the space b literie neuve qualit espace ext rieur jardin possibilit faire barbeuk calme rare lisbonne b guest access b jardin terrasse veranda b other things to note b appartement rdc escalier b license number b al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/105 [00:08<02:21,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "situ rue pi tonne deux alfama cet appartement permettra vivre ur quartier typique lisbonne acc der pied nomeux lieux touristiques b the space b appartement situ cot quartier historique alfama imm diatement derri re panth ur plus connu march puces ville feira da ladra trouve rue calme paisible ferm e circulation rez chauss e immeuble compos appartements totalement meubl tout dont besoin profiter jour peut accueillir jusqu personnes chames coucher quip grand lit grands placards canap lit places salon dot sommier latte matelas confortable disposerez cuisine enti rement quip e r frig rateur cong lateur four cuisini re gaz feux hotte lave vaissel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/105 [00:09<02:21,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faites plein aventures travers routes incroyables portugal pleine for long littoral itin raire b license number b exempt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/105 [00:11<02:18,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logement proche miradouro santa catarina logement parfait couples voyageurs solo voyageurs affaires familles enfants charmant duplex enti rement quip b ficiant chauffage central dispose toutes commodit possibles b guest access b ensemble appartement r serv locataires b license number b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 9/105 [00:12<02:17,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apr avoir r nov cor mat riaux nobles anciens cet appartement famille lisbo devenu petite merveille ravie pouvoir partager joies procure lorsqu habite quel bonheur pouvoir enfin profiter apr an mois travaux terrasses prendre petit jeuner doux soleil matin tout admirant paysages typiques lisbonne toits tage christ fameux pont suspendu b the space b situ quartier historique donnant grande cour arbor e appartement pr serv uit agr able jour nuit terrasse intime roof top panoramique permettent choisir chaque heure jour soir endroit pr dilection tendre lire admirer toits prendre petit jeuner bain soleil ambiance si particuli re cette ville moindre b tisse ruine belle visiteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 10/105 [00:14<02:21,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profitez logement enti rement refait neuf lumineux gant central coeur quartiers historiques lisbonne gra a castelo sao jorge alfama b the space b appartement lumineux disposant jour cuisine enti rement quip e coration soign e profiterez galement salle bains douche italienne belle chame disposant coin bureau appartement climatis b other things to note b check in font entre h h apr h check in possibles suppl ment payable arriv e b license number b al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 11/105 [00:15<02:17,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tendez logement calme gant b license number b exempt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 12/105 [00:17<02:12,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chame mme pompadour revivez faste versailles temps nuit deux glissez r favorite roi chame romantique nuit e charme deux chame tr calme belle salle bains grande douche mare parking place linge toilette produits toilette serviette piscine inclus b the space b petits jeuners inclus deux personnes servis petit salon parc acc piscine chauff e bain minuit autoris h h matin bar cocktails salon commun chemin e place enfants non accept animaux non autoris parking ferm quinta motos b license number b al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 13/105 [00:18<02:11,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studio donnant piscine jardin entr e ind pendante equip lave linge r frig rateur machine caf bouilloire grille pain micro onde vaisselle petite salle eau douche lavabo toilette coin bureau chaise parking quinta petits jeuners compris prix linge produits toilette serviette piscine b the space b acc piscine chauff e nage contre courant terrasse transats coin repos parc logement id al auteurs crivains tudiant etc calme reposant wifi bbq churasquero accessible clients cuisine autoris e studio seul r chauffement plats autoris petits jeuners servis petit salon biblioth salle commune chemin e partager autres clients b license number b al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 14/105 [00:19<02:07,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logement paisible offre jour tente toute famille cette maison famille nich e petit village typique proche plage mn voiture proximit sites touristiques peniche obidos mn bombaral mn nazar mn lisbonne mn village petite sup rette disponible courses h maguy jacques pr sents conseiller visites b license number b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 15/105 [00:21<02:03,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logement tr confortable fonctionnel a petit balcon vue remplie charme lisbonne autre poque situ eme tage immeuble tages logement contient deux chames dont vue jardin cuisine tr moderne toute quip acc terrasse escaliers arri re immeuble pourrais couvrir belle vue taje b the space b tr bel appartement confortable chaleureux plein centre historique belle vue raconte presque but histoire architecture contrast hauts plafonds logement donnent fra cheur naturel impression espace jardin terrasse priv partager entre deux logements accessible escaliers marquise logement tres confortable vue jardim taje b guest access b voyageur acc toutes pi b other things to note\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 16/105 [00:22<02:01,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chames glamour sexy jours couples forfait sp cial copains quinta r serv e pr sence propri taires place enfants non accept petits jeuners compris prix servis petit salon parc note chame suite harem compos e deux chames communiquent entre elles moucharabieh salle bain partag e deux chames b the space b grand parc deux hectares jardins fontaine cascade aucun vis vis piscine chauff e nage contre courant transats lits piscine salon ext rieur espace terrasse ave table chaises bain minuit autoris bbq disposition espace ext rieur si besoin cuisine chames espace service frigo machine caf micro ondes etc b guest access b a deux lisbonne campagne quinta tant peu isol e recommando\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 17/105 [00:23<01:59,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appartement mouraria palacio libelula refuge exceptionnel ur lisbonne b ficie vue couper souffle permet profiter chaque jour coucher soleil vue cristo rei tage pont avril colline ch teau ascenseur couvent santa justa a arri re appartement cour priv e appartement situ tage petit immeuble typique fa ade azulejos portugais b license number b al\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 18/105 [00:25<01:56,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "venez entrez cet endroit plein charme enti rement restaur alliant bois vieilles pierres azulejos aussi tout confort moderne plein coeur centre historique alfama calme proche toutes commodit restaurants typiques proposant soir fado id al payser passer jourromantique b the space b appartement ancien enti rement r nov typique alfama bien situ spacieux meubl gout amateurs charme romantisme b guest access b logement tres calme frais enti rement di jolie chame salon salle manger cuisine ind pendante enti rement quip e appartement comporte double vitrage manquez vers entr e immeuble magnifique oranger borde escalier menant miradouro tramway ch teau saint georges place commerce minutes pieds splendide vue rio tejo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 19/105 [00:26<02:04,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "must terrasse panoramique appartement charme chames wifi quipement moderne superbe terrasse toit vue lisbonne bordure quartier historique gra a transports mn pied tram tro anjos couvrez lisbonne pied depuis lieu jour quartier authentique typique lisbo b the space b appartement charme vue panoramique splendide bordure quartier gra a spacieux terrasse lumineux traversant exposition ouest appartement contemporain pouvant accueillir entre personnes chames lit autre possibilit dormir canap salon panorama ville verdure id al couple groupe amis famille enfants cuisine totalement quip e moderne prenez petit jeuner profitant vue depuis salle manger superbe terrasse a tres tram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 19/105 [00:27<02:03,  1.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m download(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m columns_to_apply \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhost_about\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m merged_df_french[columns_to_apply] \u001b[39m=\u001b[39m merged_df_french[columns_to_apply]\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: preprocessing_fr(row\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m      5\u001b[0m                                                                                                                      tokenize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m                                                                                                                      stop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m                                                                                                                      lemmatize \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m      8\u001b[0m                                                                                                                      stemmertize \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m                                                                                                                     )\n\u001b[0;32m     10\u001b[0m                                                                                          )\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[171], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m download(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m columns_to_apply \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhost_about\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m merged_df_french[columns_to_apply] \u001b[39m=\u001b[39m merged_df_french[columns_to_apply]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preprocessing_fr(row\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m      5\u001b[0m                                                                                                                      tokenize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m                                                                                                                      stop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m                                                                                                                      lemmatize \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m      8\u001b[0m                                                                                                                      stemmertize \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m                                                                                                                     )\n\u001b[0;32m     10\u001b[0m                                                                                          )\n",
      "Cell \u001b[1;32mIn[170], line 28\u001b[0m, in \u001b[0;36mpreprocessing_fr\u001b[1;34m(row, tokenize, stop, lemmatize, stemmertize)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m#Lemmatize\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m lemmatize:\n\u001b[1;32m---> 28\u001b[0m     lemma_fr \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mfr_core_news_md\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     29\u001b[0m     doc \u001b[39m=\u001b[39m lemma_fr(text)\n\u001b[0;32m     30\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m doc:\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:442\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:478\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \n\u001b[0;32m    463\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 478\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, enable\u001b[39m=\u001b[39;49menable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\fr_core_news_md\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:659\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    658\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[1;32m--> 659\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[0;32m    660\u001b[0m     data_path,\n\u001b[0;32m    661\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    662\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    663\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    664\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    665\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    666\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    667\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:524\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    515\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[0;32m    516\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[0;32m    517\u001b[0m     config,\n\u001b[0;32m    518\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[0;32m    523\u001b[0m )\n\u001b[1;32m--> 524\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39;49mfrom_disk(model_path, exclude\u001b[39m=\u001b[39;49mexclude, overrides\u001b[39m=\u001b[39;49moverrides)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\language.py:2125\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[1;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mexists() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m   2123\u001b[0m     \u001b[39m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m     exclude \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(exclude) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2125\u001b[0m util\u001b[39m.\u001b[39;49mfrom_disk(path, deserializers, exclude)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m path  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   2127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_link_components()\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:1369\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   1367\u001b[0m     \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[1;32m-> 1369\u001b[0m         reader(path \u001b[39m/\u001b[39;49m key)\n\u001b[0;32m   1370\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\language.py:2101\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeserialize_vocab\u001b[39m(path: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m-> 2101\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mfrom_disk(path, exclude\u001b[39m=\u001b[39;49mexclude)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\vocab.pyx:492\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\vectors.pyx:629\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:1365\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_disk\u001b[39m(\n\u001b[0;32m   1361\u001b[0m     path: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m   1362\u001b[0m     readers: Dict[\u001b[39mstr\u001b[39m, Callable[[Path], \u001b[39mNone\u001b[39;00m]],\n\u001b[0;32m   1363\u001b[0m     exclude: Iterable[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   1364\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Path:\n\u001b[1;32m-> 1365\u001b[0m     path \u001b[39m=\u001b[39m ensure_path(path)\n\u001b[0;32m   1366\u001b[0m     \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   1367\u001b[0m         \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m         \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:366\u001b[0m, in \u001b[0;36mensure_path\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Set a custom Language class name that can be loaded via get_lang_class.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m \u001b[39m    name (str): Name of Language class.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[39m    cls (Language): Language class.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     registry\u001b[39m.\u001b[39mlanguages\u001b[39m.\u001b[39mregister(name, func\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m)\n\u001b[1;32m--> 366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mensure_path\u001b[39m(path: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    367\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure string is converted to a Path.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[0;32m    369\u001b[0m \u001b[39m    path (Any): Anything. If string, it's converted to Path.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m    RETURNS: Path or original argument.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "download('wordnet')\n",
    "download('stopwords')\n",
    "columns_to_apply = ['description', 'host_about', 'comments']\n",
    "merged_df_french[columns_to_apply] = merged_df_french[columns_to_apply].astype(str).apply(lambda x: preprocessing_fr(row=x,\n",
    "                                                                                                                     tokenize=True,\n",
    "                                                                                                                     stop=True,\n",
    "                                                                                                                     lemmatize = True, \n",
    "                                                                                                                     stemmertize = False\n",
    "                                                                                                                    )\n",
    "                                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>host_about</th>\n",
       "      <th>comments</th>\n",
       "      <th>unlisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[a, v, o, i, r]</td>\n",
       "      <td>[e]</td>\n",
       "      <td>[e]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>[r]</td>\n",
       "      <td>[o]</td>\n",
       "      <td>[a, v, o, i, r]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>[a, v, o, i, r]</td>\n",
       "      <td>[x]</td>\n",
       "      <td>[e]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>[b]</td>\n",
       "      <td>[e]</td>\n",
       "      <td>[e]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329</td>\n",
       "      <td>[p]</td>\n",
       "      <td>[r]</td>\n",
       "      <td>[e]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      description host_about         comments  unlisted\n",
       "0      5  [a, v, o, i, r]        [e]              [e]         0\n",
       "1    189              [r]        [o]  [a, v, o, i, r]         0\n",
       "2    192  [a, v, o, i, r]        [x]              [e]         0\n",
       "3    301              [b]        [e]              [e]         0\n",
       "4    329              [p]        [r]              [e]         1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_french.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join all Portuguese host_about/desc with Portuguese comments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_pt = create_df(df_train_detected, df_train_reviews_detected, \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>host_about</th>\n",
       "      <th>comments</th>\n",
       "      <th>unlisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>O proprietário recebe os hospedes pessoalmente...</td>\n",
       "      <td>Faço questão de receber os hospedes, para que ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>Simplifique neste espaço tranquilo e de locali...</td>\n",
       "      <td>Ola sou Carla, tenho prazer em recebê-los em m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>Apartamento composto por uma suite, sala de es...</td>\n",
       "      <td>Apaixonada por Portugal!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>O apartamento está decorado com extremo bom go...</td>\n",
       "      <td>Sou uma pessoa otimista que vive a vida com a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>Óptimo espaço exterior, ideal para quem gosta ...</td>\n",
       "      <td>O meu nome é Cátia, nasci e cresci em Sintra, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>12457</td>\n",
       "      <td>Casa aconchegante familiar &lt;br /&gt;Com ótimas co...</td>\n",
       "      <td>Boa pessoa</td>\n",
       "      <td>index\\n12457    Excelente localização, boas ár...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>12461</td>\n",
       "      <td>Bem vindo a Lisboa!&lt;br /&gt;Este charmoso apartam...</td>\n",
       "      <td>Tenho 38 anos e sou Assistente social de forma...</td>\n",
       "      <td>index\\n12461    Excelente apartamento. Um agra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>12470</td>\n",
       "      <td>Apartamento para 6 pessoas com 2 quartos, sala...</td>\n",
       "      <td>Chamo-me Margarida. Gosto do mar, praia, do so...</td>\n",
       "      <td>index\\n12470    quem quiser passar uns dias nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>12476</td>\n",
       "      <td>Apartamento numa zona muito calma de Lisboa, m...</td>\n",
       "      <td>O apartamento é muito, muito simples, mas tem ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>12495</td>\n",
       "      <td>A Terra da Eira é uma casa de campo rodeada de...</td>\n",
       "      <td>Somos uma familia de 5. Gostamos de viajar e d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                        description  \\\n",
       "0        13  O proprietário recebe os hospedes pessoalmente...   \n",
       "1        34  Simplifique neste espaço tranquilo e de locali...   \n",
       "2        64  Apartamento composto por uma suite, sala de es...   \n",
       "3        67  O apartamento está decorado com extremo bom go...   \n",
       "4        87  Óptimo espaço exterior, ideal para quem gosta ...   \n",
       "...     ...                                                ...   \n",
       "1084  12457  Casa aconchegante familiar <br />Com ótimas co...   \n",
       "1085  12461  Bem vindo a Lisboa!<br />Este charmoso apartam...   \n",
       "1086  12470  Apartamento para 6 pessoas com 2 quartos, sala...   \n",
       "1087  12476  Apartamento numa zona muito calma de Lisboa, m...   \n",
       "1088  12495  A Terra da Eira é uma casa de campo rodeada de...   \n",
       "\n",
       "                                             host_about  \\\n",
       "0     Faço questão de receber os hospedes, para que ...   \n",
       "1     Ola sou Carla, tenho prazer em recebê-los em m...   \n",
       "2                              Apaixonada por Portugal!   \n",
       "3     Sou uma pessoa otimista que vive a vida com a ...   \n",
       "4     O meu nome é Cátia, nasci e cresci em Sintra, ...   \n",
       "...                                                 ...   \n",
       "1084                                        Boa pessoa    \n",
       "1085  Tenho 38 anos e sou Assistente social de forma...   \n",
       "1086  Chamo-me Margarida. Gosto do mar, praia, do so...   \n",
       "1087  O apartamento é muito, muito simples, mas tem ...   \n",
       "1088  Somos uma familia de 5. Gostamos de viajar e d...   \n",
       "\n",
       "                                               comments  unlisted  \n",
       "0                                                   NaN         0  \n",
       "1                                                   NaN         1  \n",
       "2                                                   NaN         1  \n",
       "3                                                   NaN         0  \n",
       "4                                                   NaN         1  \n",
       "...                                                 ...       ...  \n",
       "1084  index\\n12457    Excelente localização, boas ár...         0  \n",
       "1085  index\\n12461    Excelente apartamento. Um agra...         0  \n",
       "1086  index\\n12470    quem quiser passar uns dias nu...         0  \n",
       "1087                                                NaN         0  \n",
       "1088                                                NaN         1  \n",
       "\n",
       "[1089 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.5.0/pt_core_news_sm-3.5.0-py3-none-any.whl (13.0 MB)\n",
      "                                              0.0/13.0 MB ? eta -:--:--\n",
      "     -                                        0.4/13.0 MB 13.9 MB/s eta 0:00:01\n",
      "     --                                       0.9/13.0 MB 11.3 MB/s eta 0:00:02\n",
      "     ----                                     1.4/13.0 MB 10.9 MB/s eta 0:00:02\n",
      "     ------                                   2.1/13.0 MB 12.1 MB/s eta 0:00:01\n",
      "     --------                                 2.8/13.0 MB 12.7 MB/s eta 0:00:01\n",
      "     ----------                               3.4/13.0 MB 12.9 MB/s eta 0:00:01\n",
      "     ------------                             4.1/13.0 MB 13.0 MB/s eta 0:00:01\n",
      "     --------------                           4.8/13.0 MB 13.3 MB/s eta 0:00:01\n",
      "     ----------------                         5.4/13.0 MB 13.4 MB/s eta 0:00:01\n",
      "     -------------------                      6.2/13.0 MB 13.2 MB/s eta 0:00:01\n",
      "     --------------------                     6.8/13.0 MB 13.5 MB/s eta 0:00:01\n",
      "     ----------------------                   7.4/13.0 MB 13.5 MB/s eta 0:00:01\n",
      "     ------------------------                 7.9/13.0 MB 13.3 MB/s eta 0:00:01\n",
      "     --------------------------               8.6/13.0 MB 13.4 MB/s eta 0:00:01\n",
      "     ----------------------------             9.2/13.0 MB 13.3 MB/s eta 0:00:01\n",
      "     ------------------------------           9.9/13.0 MB 13.4 MB/s eta 0:00:01\n",
      "     -------------------------------         10.6/13.0 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------------       11.2/13.0 MB 13.9 MB/s eta 0:00:01\n",
      "     -----------------------------------     11.7/13.0 MB 13.9 MB/s eta 0:00:01\n",
      "     -------------------------------------   12.4/13.0 MB 13.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.9/13.0 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 13.0/13.0 MB 12.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from pt-core-news-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leoal\\.virtualenvs\\project-anjsu91q\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.1.3)\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pt(row, tokenize, stop, lemmatize, stemmertize):\n",
    "    updates = []\n",
    "    \n",
    "    for j in tqdm(row):\n",
    "        \n",
    "        text = j\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA and PUNCTUATION\n",
    "        text = re.sub(\"[^a-zA-Z]\",\" \", text )\n",
    "        text = re.sub(\"br\", \"\", text)\n",
    "\n",
    "        if tokenize:\n",
    "            tokens = word_tokenize(text, language=\"portuguese\")\n",
    "            text = \" \".join(tokens)\n",
    "            \n",
    "        #REMOVE STOPWORDS\n",
    "        if stop:\n",
    "            stop_pt = set(stopwords.words('portuguese'))\n",
    "            text = \" \".join([word for word in text.split() if word not in stop_pt])\n",
    "            \n",
    "        #Lemmatize\n",
    "        if lemmatize:\n",
    "            lemma_pt = spacy.load(\"pt_core_news_sm\")\n",
    "            doc = lemma_pt(text)\n",
    "            for word in doc:\n",
    "                text = \" \".join(word.lemma_).split()\n",
    "        \n",
    "        #Stemming\n",
    "        if stemmertize:\n",
    "            stemmer_pt = RSLPStemmer()\n",
    "            stem_doc = stemmer_pt(text)\n",
    "            for word in stem_doc:\n",
    "                text = \" \".join(stemmer_pt.stem(word) for word in text.split())\n",
    "            \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\leoal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leoal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      " 19%|█▊        | 203/1089 [00:52<03:47,  3.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m download(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m columns_to_apply \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhost_about\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m merged_df_pt[columns_to_apply] \u001b[39m=\u001b[39m merged_df_pt[columns_to_apply]\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: preprocessing_pt(text_list\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m      5\u001b[0m                                                                                                              tokenize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m                                                                                                              stop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m                                                                                                              lemmatize \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m      8\u001b[0m                                                                                                              stemmertize \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m                                                                                                             )\n\u001b[0;32m     10\u001b[0m                                                                                 )\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[153], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m download(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m columns_to_apply \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhost_about\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m merged_df_pt[columns_to_apply] \u001b[39m=\u001b[39m merged_df_pt[columns_to_apply]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preprocessing_pt(text_list\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m      5\u001b[0m                                                                                                              tokenize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m                                                                                                              stop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m                                                                                                              lemmatize \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m      8\u001b[0m                                                                                                              stemmertize \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m                                                                                                             )\n\u001b[0;32m     10\u001b[0m                                                                                 )\n",
      "Cell \u001b[1;32mIn[152], line 26\u001b[0m, in \u001b[0;36mpreprocessing_pt\u001b[1;34m(text_list, tokenize, stop, lemmatize, stemmertize)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m#Lemmatize\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m lemmatize:\n\u001b[1;32m---> 26\u001b[0m     lemma_pt \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mpt_core_news_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     27\u001b[0m     doc \u001b[39m=\u001b[39m lemma_pt(text)\n\u001b[0;32m     28\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m doc:\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:442\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:478\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \n\u001b[0;32m    463\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 478\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, enable\u001b[39m=\u001b[39;49menable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\pt_core_news_sm\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:659\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    658\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[1;32m--> 659\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[0;32m    660\u001b[0m     data_path,\n\u001b[0;32m    661\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    662\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    663\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    664\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m    665\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    666\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    667\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:524\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    515\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[0;32m    516\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[0;32m    517\u001b[0m     config,\n\u001b[0;32m    518\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[0;32m    523\u001b[0m )\n\u001b[1;32m--> 524\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39;49mfrom_disk(model_path, exclude\u001b[39m=\u001b[39;49mexclude, overrides\u001b[39m=\u001b[39;49moverrides)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\language.py:2125\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[1;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mexists() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m   2123\u001b[0m     \u001b[39m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m     exclude \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(exclude) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2125\u001b[0m util\u001b[39m.\u001b[39;49mfrom_disk(path, deserializers, exclude)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m path  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   2127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_link_components()\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:1369\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   1367\u001b[0m     \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[1;32m-> 1369\u001b[0m         reader(path \u001b[39m/\u001b[39;49m key)\n\u001b[0;32m   1370\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\language.py:2101\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeserialize_vocab\u001b[39m(path: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m-> 2101\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mfrom_disk(path, exclude\u001b[39m=\u001b[39;49mexclude)\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\vocab.pyx:492\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\vectors.pyx:629\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:1365\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_disk\u001b[39m(\n\u001b[0;32m   1361\u001b[0m     path: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m   1362\u001b[0m     readers: Dict[\u001b[39mstr\u001b[39m, Callable[[Path], \u001b[39mNone\u001b[39;00m]],\n\u001b[0;32m   1363\u001b[0m     exclude: Iterable[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   1364\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Path:\n\u001b[1;32m-> 1365\u001b[0m     path \u001b[39m=\u001b[39m ensure_path(path)\n\u001b[0;32m   1366\u001b[0m     \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   1367\u001b[0m         \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m         \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n",
      "File \u001b[1;32mc:\\Users\\leoal\\.virtualenvs\\Project-aNjsu91Q\\lib\\site-packages\\spacy\\util.py:366\u001b[0m, in \u001b[0;36mensure_path\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Set a custom Language class name that can be loaded via get_lang_class.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m \u001b[39m    name (str): Name of Language class.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[39m    cls (Language): Language class.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     registry\u001b[39m.\u001b[39mlanguages\u001b[39m.\u001b[39mregister(name, func\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m)\n\u001b[1;32m--> 366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mensure_path\u001b[39m(path: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    367\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure string is converted to a Path.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[0;32m    369\u001b[0m \u001b[39m    path (Any): Anything. If string, it's converted to Path.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m    RETURNS: Path or original argument.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "download('wordnet')\n",
    "download('stopwords')\n",
    "columns_to_apply = ['description', 'host_about', 'comments']\n",
    "merged_df_pt[columns_to_apply] = merged_df_pt[columns_to_apply].astype(str).apply(lambda row: preprocessing_pt(row=row,\n",
    "                                                                                                             tokenize=True,\n",
    "                                                                                                             stop=True,\n",
    "                                                                                                             lemmatize = True, \n",
    "                                                                                                             stemmertize = False\n",
    "                                                                                                            )\n",
    "                                                                                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leoal\\AppData\\Local\\Temp\\ipykernel_19032\\525845318.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df_english['Concatenated_Text'] = merged_df_english['description'] + ' ' + merged_df_english['host_about'] + ' ' + merged_df_english['comments']\n"
     ]
    }
   ],
   "source": [
    "# Concatenate text columns into a single column\n",
    "merged_df_english['Concatenated_Text'] = merged_df_english['description'] + ' ' + merged_df_english['host_about'] + ' ' + merged_df_english['comments']\n",
    "\n",
    "#separate features and taget\n",
    "X = merged_df_english['Concatenated_Text']\n",
    "y = merged_df_english['unlisted']\n",
    "\n",
    "X_train, X_val , y_train, y_val = train_test_split(X, y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train.values.ravel())\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_val.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9037172455819622\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = rf_classifier.score(X_test_tfidf, y_val)\n",
    "print(\"Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelknn_word = KNeighborsClassifier(n_neighbors = 10, metric = 'cosine', weights = 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;cosine&#x27;, n_neighbors=10, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;cosine&#x27;, n_neighbors=10, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='cosine', n_neighbors=10, weights='distance')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelknn_word.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = modelknn_word.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8488726386349786\n"
     ]
    }
   ],
   "source": [
    "accuracy_knn = modelknn_word.score(X_test_tfidf, y_val)\n",
    "print(\"Accuracy:\", accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(row):\n",
    "    lang = detect(row)\n",
    "    if lang == \"en\":\n",
    "        preprocessing_eng(row)\n",
    "        return model_eng.predict(row)\n",
    "    elif lang == \"fr\":\n",
    "        preprocessing_fr(row)\n",
    "        return model_fr.predict(row)\n",
    "    elif lang == \"pt\":\n",
    "        preprocessing_pt(row)\n",
    "        return model_pt.predict(row)\n",
    "    else:\n",
    "        translate_to_english\n",
    "        preprocessing_eng(row)\n",
    "        return model_eng.predict(row)\n",
    "\n",
    "\n",
    "df_test_[\"prediction\"] = df.apply(lambda row: prediction(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
